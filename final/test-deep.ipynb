{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "from torch import tensor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "import torch.nn.functional as F\n",
    "from skimage import io, color\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchmetrics import JaccardIndex, Dice\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import jaccard_score\n",
    "import gc\n",
    "from USSFCNet import USSFCNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images from folders A and B\n",
    "folder_A = 'testval/A'\n",
    "folder_B = 'testval/B'\n",
    "folder_label = 'testval/label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\") # Use GPU or CPU for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load images from directory\n",
    "def load_images_from_folder(folder, is_gray = True):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = io.imread(os.path.join(folder,filename)).astype(np.uint8)\n",
    "        if img is not None:\n",
    "            if is_gray:\n",
    "                images.append(color.rgb2gray(img))\n",
    "            else:    \n",
    "                images.append(img)\n",
    "    return images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_A = load_images_from_folder(folder_A, is_gray=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_B = load_images_from_folder(folder_B, is_gray=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = load_images_from_folder(folder_label, is_gray = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200 1200 1200\n"
     ]
    }
   ],
   "source": [
    "print(len(images_A), len(images_B), len(labels)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0.5, 0.5, 0.5),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChangeDetectionDataset(Dataset):\n",
    "    def __init__(self, images_A, images_B, labels):\n",
    "        self.images_A = images_A\n",
    "        self.images_B = images_B\n",
    "        self.labels = labels\n",
    "#         self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_A = torch.tensor(self.images_A[idx], dtype=torch.float32).permute(2, 0, 1) / 255\n",
    "        image_B = torch.tensor(self.images_B[idx], dtype=torch.float32).permute(2, 0, 1) / 255\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float32) / 255\n",
    "\n",
    "#         if self.transform:\n",
    "#             image_A = self.transform(image_A)\n",
    "#             image_B = self.transform(image_B)\n",
    "#             label = self.transform(label)\n",
    "\n",
    "        return image_A, image_B, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = USSFCNet(in_ch=3, out_ch=1, ratio=0.5).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = 'model_now_2.pickle'\n",
    "model.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:28<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Jaccard Index : 0.039073289064563976 | Jaccard Avg : 0.08604966808773329 \n"
     ]
    }
   ],
   "source": [
    "dataset = ChangeDetectionDataset(images_A, images_B, labels)\n",
    "data_loader = DataLoader(dataset, batch_size=16)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model.eval()\n",
    "val_total_intersections = 0\n",
    "val_total_unions = 0\n",
    "with torch.no_grad():\n",
    "    jaccardArr = []\n",
    "    for a, b, l in tqdm(data_loader):\n",
    "        a, b, l = a.to(device), b.to(device), l.to(device)\n",
    "        outputs = model(a,b)\n",
    "        outputs = outputs.reshape((-1,l.shape[1],l.shape[2]))\n",
    "        outputs_binary = (outputs>0.5) * 1\n",
    "        val_total_intersections += np.logical_and(outputs_binary.cpu().numpy(), l.cpu().numpy()).sum()\n",
    "        val_total_unions += np.logical_or(outputs_binary.cpu().numpy(), l.cpu().numpy()).sum()\n",
    "        for i in range(len(outputs_binary)):\n",
    "            intersection = np.logical_and(outputs_binary[i].cpu().numpy(), l[i].cpu().numpy()).sum()\n",
    "            union = np.logical_or(outputs_binary[i].cpu().numpy(), l[i].cpu().numpy()).sum()\n",
    "            if union != 0:\n",
    "                jaccardArr.append((intersection)/(union))\n",
    "            else:\n",
    "                jaccardArr.append(1)\n",
    "val_jaccard = val_total_intersections / val_total_unions\n",
    "secondWay = np.array(jaccardArr).mean()\n",
    "print(f'Validation Jaccard Index : {val_jaccard} | Jaccard Avg : {secondWay} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
